{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"ThorVision  <p>     A GUI app for seamless control and video capture from USB cameras on the XDAQ AIO. </p> <p> </p>"},{"location":"#features","title":"Features","text":"<ul> <li>Works automatically with the XDAQ AIO</li> <li>Record videos with embedded XDAQ Metadata</li> <li>Record M-JPEG encoded videos</li> </ul> <p>Note</p> <ul> <li>Record H.265 encoded videos (coming soon)</li> <li>Synchronized recording with Open Ephys GUI and XDAQ-RHX (coming soon)</li> <li>Trigger recording from hardware TTL inputs or via Brainwave simulator (coming soon)</li> </ul>"},{"location":"#platforms","title":"Platforms","text":"<ul> <li>Windows</li> <li>macOS</li> </ul> <p>Note</p> <p>Support for Ubuntu is in development (coming soon)</p>"},{"location":"FAQs/","title":"Frequently Asked Questions","text":"<p>A collection of FAQs our customers find it helpful.</p>"},{"location":"FAQs/#where-can-i-purchase-xdaq-aio","title":"Where can I purchase XDAQ AIO?","text":"<ol> <li>Visit the XDAQ AIO webpage.</li> <li>Click <code>Add to Wishlist</code>.</li> <li>Go to <code>Wishlist</code> at the top of the website and select <code>Quote Wishlist</code>.</li> <li>Fill in the required information and click <code>Submit Quote</code>.</li> </ol>"},{"location":"FAQs/#no-preview-after-initial-setup","title":"No Preview After Initial Setup?","text":"<p>Re-select the same <code>Quality</code> / <code>Codec</code> once.</p> <p>If the issue persists, repeat the Launch Sequence.</p>"},{"location":"FAQs/#lost-connection","title":"Lost Connection?","text":"<p>Confirm all cables are secure, then wait for the XDAQ status to update (approx. 6 seconds).</p> <p>If the issue persists, repeat the Launch Sequence.</p>"},{"location":"FAQs/#preview-frozen-after-a-mid-demo-change","title":"Preview Frozen After a Mid-Demo Change?","text":"<p>Repeat the Launch Sequence.</p>"},{"location":"FAQs/#how-can-i-ensure-video-synchronization-between-usb-cameras-and-headstage-signals","title":"How can I ensure video synchronization between USB cameras and Headstage signals?","text":"<p>We provide detailed documentation on how we measure camera latency and metadata processing the camera frame with headstage signals acquire by XDAQ-RHX.</p> <p>Note</p> <p>Support for Open Ephys GUI is in development (coming soon).</p>"},{"location":"FAQs/#why-arent-my-cameras-working","title":"Why aren't my cameras working?","text":"<p>If you're experiencing issues with USB cameras, please refer to our USB cameras documentation for troubleshooting steps and compatibility information.</p>"},{"location":"FAQs/#how-can-i-provide-feature-suggestions-or-contribute-to-the-app","title":"How can I provide feature suggestions or contribute to the app?","text":"<p>We welcome feedback and feature suggestions! Please submit your ideas and feature requests on our GitHub Issues page.</p> <p>If you have any further questions or need additional assistance, feel free to contact us at support@kontex.io.</p>"},{"location":"camera-latency/","title":"Camera Latency","text":"<p>We conducted experiments to evaluate the latency in our camera system. Our results indicate that most timestamp discrepancies fall within approximately \\(5.314\\, \\text{ms}\\). This is well within the frame duration of cameras operating below \\(188\\, \\text{fps}\\) (roughly \\(5.32\\, \\text{ms}\\) per frame), ensuring that neural data remains correctly aligned with the corresponding video frame even if a slight latency error occurs.</p>"},{"location":"camera-latency/#experiment-setup","title":"Experiment Setup","text":"<ul> <li> <p>High-Speed Camera:   Operates at \\(596\\, \\text{fps}\\), which allows us to sample the LED signal at \\(596\\, \\text{Hz}\\).</p> </li> <li> <p>LEDs:   Used to indicate the FPGA timestamp.</p> </li> <li> <p>ThorVision Software Stack:   Employed for recording video frames and saving the corresponding XDAQ timestamp in each frame.</p> </li> </ul>"},{"location":"camera-latency/#methodology","title":"Methodology","text":"<p>The system's total latency is measured from the FPGA to the Timestamp Query Buffer. The diagrams below illustrate the propagation pipeline and the step-by-step calculation:</p> <p></p>"},{"location":"camera-latency/#latency-calculation-steps","title":"Latency Calculation Steps","text":"<ol> <li> <p>Neglecting Initial Delays:     We assume that the delays in the initial stages (steps 1 and 2 in the pipeline) are negligible. Therefore, we approximate:</p> \\[ t'' \\approx t \\] </li> <li> <p>Adjusting for Offset:     The query buffer timestamp is offset by a delay \\(a\\). In other words:</p> \\[ t' = t - a \\] </li> <li> <p>Measurement Process:</p> <ul> <li>Timestamp Difference: Measure the difference between the new query buffer timestamp and the old FPGA LED timestamp:</li> </ul> \\[ \\Delta t = t^{\\prime}_{\\text{new}} - t^{\\prime\\prime}_{\\text{old}} \\] <ul> <li>Roundtrip Delay: Independently, determine the roundtrip delay, which corresponds to \\(2a\\).   $$   \\text{Roundtrip Delay} = 2a   $$</li> </ul> </li> </ol> <p>Total Latency Calculation:   The combined latency can then be expressed as:    $$    Latency = \\Delta t + a    $$</p> <p>The second diagram provides further details on these steps:</p> <p></p>"},{"location":"camera-latency/#results","title":"Results","text":"<ul> <li>Measured Timestamp Difference (\\(t'_{\\text{new}} - t''_{\\text{old}}\\)):<ul> <li>Upper Bound: \\(5.12\\, \\text{ms}\\)</li> <li>Average: \\(2.94\\, \\text{ms}\\)</li> </ul> </li> <li>Offset Value (\\(a\\)):<ul> <li>Maximum: \\(a \\leq 0.194\\, \\text{ms}\\)</li> </ul> </li> <li>Calculated Latency:<ul> <li>Upper Bound:   $$   \\text{Latency}_{\\text{upper}} = 5.12\\, \\text{ms} + 0.194\\, \\text{ms} = 5.314\\, \\text{ms}   $$</li> <li>Average:   $$   \\text{Latency}_{\\text{avg}} = 2.94\\, \\text{ms} + 0.194\\, \\text{ms} = 3.134\\, \\text{ms}   $$</li> </ul> </li> </ul>"},{"location":"camera-latency/#conclusion","title":"Conclusion","text":"<p>For optimal performance, it is recommended that your camera operates at or below \\(188\\, \\text{fps}\\). This ensures that the frame duration comfortably accommodates the measured latency margin, thereby maintaining reliable synchronization between video frames and neural data.</p>"},{"location":"deployment/","title":"Deployment","text":"<p>To successfully deploy the app, follow the steps outlined in Build the app. Then, generate the build files with the <code>-DCMAKE_INSTALL_PREFIX=\"./&lt;folder&gt;</code> option enabled, and compile the target with <code>package</code>.</p> <ol> <li> <p>Generate the build files with a custom installation directory: <pre><code>cmake -S . -B build/Release --preset conan-release -G \"Ninja\" -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=\"./&lt;folder&gt;\"\n</code></pre></p> </li> <li> <p>Build and package the app: <pre><code>cmake --build build/Release --preset conan-release --target package\n</code></pre></p> </li> </ol>"},{"location":"getting-started/","title":"Getting Started","text":"<p>Welcome to the ThorVision developer docs! This guide will walk you through building and deploying the app from source.</p>"},{"location":"getting-started/#building-from-source-coming-soon","title":"Building from Source (coming soon)","text":"<p>Before you begin, ensure the following tools and dependencies are installed on your system:</p>"},{"location":"getting-started/#install-build-tools","title":"Install Build Tools","text":"<ul> <li>CMake - Cross-platform build system generator<ul> <li>Download CMake 3.27 (or higher) installer from https://cmake.org/download/ and install it.</li> </ul> </li> <li>Conan - Software package manager for C++</li> <li>git - Version control system<ul> <li>Download git installer from https://git-scm.com/downloads/win and install it.</li> </ul> </li> <li>Ninja - Small build system with a focus on speed</li> <li>Python - Programming language<ul> <li>Download Python 3.12 (or higher) installer from https://www.python.org/downloads/ and install it with adding to PATH enabled.</li> </ul> </li> <li>Qt 6 - GUI framework for the app<ul> <li>Download Qt 6 installer from https://www.qt.io/download-dev and install it.</li> </ul> </li> <li>Visual Studio - C/C++ IDE and MSVC compiler for Windows<ul> <li>Download Visual Studio 2022 installer from https://visualstudio.microsoft.com/downloads/ and install it.</li> </ul> </li> </ul> <p>Note</p> <p>The build is done in Visual Studio 2022 Community with SDK version 10.0.22621.0 and Qt 6 Community Edition.</p>"},{"location":"getting-started/#install-xdaq-libraries","title":"Install XDAQ Libraries","text":"<ul> <li><code>xdaqmetadata</code> - Required for parsing XDAQ Metadata</li> <li><code>libxvc</code> - Required for streaming cameras</li> </ul>"},{"location":"getting-started/#build-xdaqmetadata","title":"Build xdaqmetadata","text":"<ol> <li> <p>Get the source code and go to project directory <pre><code>git clone https://github.com/kontex-neuro/xdaqmetadata.git\ncd xdaqmetadata\n</code></pre></p> </li> <li> <p>Create python virtual environment <code>.venv</code> in project directory and activate it <pre><code>py -m venv .venv\n.venv\\Scripts\\activate\n</code></pre></p> </li> <li> <p>Install Conan and ninja in <code>.venv</code> via pip <pre><code>pip install conan ninja\n</code></pre></p> </li> <li> <p>Install dependencies using Conan <pre><code>conan install . -b missing -pr:a &lt;profile&gt; -s build_type=Release\n</code></pre></p> </li> <li> <p>Generate the build files with CMake <pre><code>cmake -S . -B build/Release --preset conan-release -G \"Ninja\" -DCMAKE_BUILD_TYPE=Release\n</code></pre></p> </li> <li> <p>Build the project <pre><code>cmake --build build/Release --preset conan-release\n</code></pre></p> </li> <li> <p>Export as conan package to local cache <pre><code>conan export-pkg . -pr:a &lt;profile&gt; -s build_type=Release\n</code></pre></p> </li> </ol> <p>Note</p> <p>Replace <code>&lt;profile&gt;</code> with the Conan profile from your environment, To see more about how to create Conan profile.</p> <p>Example Conan profile for Windows:</p> <pre><code>[settings]\narch=x86_64\ncompiler=msvc\ncompiler.cppstd=20\ncompiler.runtime=dynamic\ncompiler.version=194\nos=Windows\n[conf]\ntools.cmake.cmaketoolchain:generator=Ninja\n</code></pre>"},{"location":"getting-started/#build-libxvc","title":"Build libxvc","text":"<ol> <li> <p>Get the source code and go to project directory <pre><code>git clone https://github.com/kontex-neuro/libxvc.git\ncd libxvc\n</code></pre></p> </li> <li> <p>Create python virtual environment <code>.venv</code> in project directory and activate it <pre><code>py -m venv .venv\n.venv\\Scripts\\activate\n</code></pre></p> </li> <li> <p>Install Conan and ninja in <code>.venv</code> via pip <pre><code>pip install conan ninja\n</code></pre></p> </li> <li> <p>Install dependencies using Conan <pre><code>conan install . -b missing -pr:a &lt;profile&gt; -s build_type=Release\n</code></pre></p> </li> <li> <p>Generate the build files with CMake <pre><code>cmake -S . -B build/Release --preset conan-release -G \"Ninja\" -DCMAKE_BUILD_TYPE=Release\n</code></pre></p> </li> <li> <p>Build the project <pre><code>cmake --build build/Release --preset conan-release\n</code></pre></p> </li> <li> <p>Export as conan package to local cache <pre><code>conan export-pkg . -pr:a &lt;profile&gt; -s build_type=Release\n</code></pre></p> </li> </ol> <p>Build order</p> <p>Be sure to build <code>xdaqmetadata</code> first then <code>libxvc</code>, since <code>libxvc</code> is depended on <code>xdaqmetadata</code>.</p>"},{"location":"getting-started/#build-the-app","title":"Build the app","text":"<p>Follow these steps to build the app from source:</p> <ol> <li> <p>Get the source code and go to project directory <pre><code>git clone https://github.com/kontex-neuro/ThorVision.git\ncd ThorVision\n</code></pre></p> </li> <li> <p>Create python virtual environment <code>.venv</code> in project directory and activate it <pre><code>py -m venv .venv\n.venv\\Scripts\\activate\n</code></pre></p> </li> <li> <p>Install Conan and ninja in <code>.venv</code> via pip <pre><code>pip install conan ninja\n</code></pre></p> </li> <li> <p>Install dependencies using Conan <pre><code>conan install . -b missing -pr:a &lt;profile&gt; -s build_type=Release\n</code></pre></p> </li> <li> <p>Generate the build files with CMake <pre><code>cmake -S . -B build/Release --preset conan-release -G \"Ninja\" -DCMAKE_BUILD_TYPE=Release\n</code></pre></p> </li> <li> <p>Build the project <pre><code>cmake --build build/Release --preset conan-release\n</code></pre></p> </li> </ol>"},{"location":"getting-started/#building-the-docs-optional","title":"Building the docs (Optional)","text":"<p>Before you begin, ensure the following tools are installed on your system:</p> <ul> <li>Python</li> <li>MkDocs with <code>mkdocs-material</code>, <code>pymdown-extensions</code> and <code>mkdocstrings</code> <pre><code>pip install mkdocs mkdocs-material pymdown-extensions mkdocstrings\n</code></pre></li> </ul> <p>First generate build files using <code>CMake</code> with the <code>-DBUILD_DOC=ON</code> option enabled. Then compile the target <code>doc</code>, for example:</p> <pre><code>cmake --build build/Release --preset conan-release --target doc\n</code></pre> <p>This will generate documentation in <code>&lt;project_directory&gt;/build/Release/site</code>.</p>"},{"location":"metadata-processing/","title":"Metadata Processing","text":"<p>This guide illustrates how to process and synchronize metadata from XDAQ binary files containing video frame information with neural recordings from Intan RHD files. It explains the file format and data structure, lists the software requirements, and provides detailed Python code examples for reading XDAQ metadata into a structured NumPy array, loading Intan neural data, and mapping neural timestamps to video frame timestamps using binary search.</p>"},{"location":"metadata-processing/#requirements","title":"Requirements","text":"<p>Ensure you have the following installed for compatibility:</p> <ul> <li>Python &gt;= 3.6 - Type hints support</li> <li>NumPy &gt;= 1.15.0 - Array operations</li> <li>Intan RHD/RHS reader - Neural data</li> </ul> <p>Note</p> <p>Although earlier versions might work, these versions are recommended.</p>"},{"location":"metadata-processing/#reading-xdaq-metadata","title":"Reading XDAQ Metadata","text":"<p>The following example shows how to read XDAQ metadata from a binary file into a structured NumPy array:</p> <pre><code>import sys\nfrom typing import Optional\nimport numpy as np\n\nmetadata_dtype = np.dtype([\n    ('fpga_timestamp', np.uint64),\n    ('rhythm_timestamp', np.uint32),\n    ('ttl_in', np.uint32),\n    ('ttl_out', np.uint32),\n    ('spi_perf_counter', np.uint32),\n    ('reserved', np.uint64)\n])\n\nrecord_dtype = np.dtype([\n    ('video_timestamp', np.uint64),\n    ('metadata', metadata_dtype)\n])\n\ndef read_XDAQFrameData_np(filename: str) -&gt; Optional[np.ndarray]:\n    \"\"\"\n    Read XDAQ metadata data file.\n\n    Args:\n        filename: Path to the metadata data file.\n\n    Returns:\n        Structured numpy array containing video timestamps and metadata.\n        Returns None if file reading fails.\n\n    Example:\n        &gt;&gt;&gt; data = read_XDAQFrameData_np(\"data.bin\")\n        &gt;&gt;&gt; print(data['video_timestamp'][0])  # First video timestamp\n        &gt;&gt;&gt; print(data['metadata']['ttl_in'][0])  # First TTL input value\n    \"\"\"\n    try:\n        with open(filename, 'rb') as f:\n            data = f.read()\n        return np.frombuffer(data, dtype=record_dtype)\n    except Exception as e:\n        print(f\"Error reading file: {e}\")\n        return None\n</code></pre> <p>Expected output:</p> <pre><code>array([(1234567890, (987654321, 1000, 1, 0, 100, 0)),\n       (1234567891, (987654322, 1001, 1, 0, 101, 0)), ...],\n      dtype=record_dtype)\n</code></pre>"},{"location":"metadata-processing/#reading-intan-data","title":"Reading Intan Data","text":"<p>The next code snippet uses the Intan Python reader to load data from an .rhd file. You can download the reader from Intan Technologies.</p> <pre><code>import sys\nfrom load_intan_rhd_format import read_data\n\nif __name__ == \"__main__\":\n    if len(sys.argv) &lt; 2:\n        print(f\"Usage: python {sys.argv[0]} &lt;file_name&gt;\")\n        sys.exit(1)\n    rhd_path = sys.argv[1]\n    intan_data = read_data(rhd_path)\n    print(f\"Loaded neural data with {len(intan_data['t_amplifier'])} samples\")\n    print(intan_data['t_amplifier'])\n    print(intan_data['amplifier_data'])\n</code></pre> <p>Usage:</p> <pre><code>python XDAQFrameData.py &lt;intan_data_file_name&gt;\n</code></pre> <p>Expected output:</p> <pre><code>Reading Intan Technologies RHD Data File, Version 3.3\n\nFound 128 amplifier channels.\nFound 6 auxiliary input channels.\nFound 0 supply voltage channels.\nFound 0 board ADC channels.\nFound 8 board digital input channels.\nFound 0 board digital output channels.\nFound 0 temperature sensors channels.\n\nFile contains 28.915 seconds of data.  Amplifiers were sampled at 30.00 kS/s.\n\nAllocating memory for data...\nReading data from file...\n10% done...\n20% done...\n30% done...\n40% done...\n50% done...\n60% done...\n70% done...\n80% done...\n90% done...\nParsing data...\nNo missing timestamps in data.\nDone!  Elapsed time: 1.2 seconds\nLoaded neural data with 867456 samples\n[0.00000000e+00 3.33333333e-05 6.66666667e-05 ... 2.89151000e+01\n 2.89151333e+01 2.89151667e+01]\n[[ 435.63   562.38   618.345 ...  533.91   531.57   527.865]\n [ 475.8    592.995  629.07  ...  633.75   629.85   624.39 ]\n [ 881.595 1027.26  1087.125 ... 1037.01  1029.795 1020.63 ]\n ...\n [  67.665   56.355   43.68  ...  300.495  300.3    292.695]\n [ 181.35   301.665  264.42  ...  187.2    186.225  180.57 ]\n [ 160.68   283.14   240.825 ...  375.375  373.815  362.505]]\n</code></pre>"},{"location":"metadata-processing/#synchronizing-xdaq-and-intan-data","title":"Synchronizing XDAQ and Intan Data","text":"<p>This example demonstrates how to map neural timestamps to the corresponding video frame timestamps using a binary search with NumPy.</p> <pre><code>import numpy as np\nimport sys\nfrom load_intan_rhd_format import read_data\n\nmetadata_dtype = np.dtype([\n    ('fpga_timestamp', np.uint64),\n    ('rhythm_timestamp', np.uint32),\n    ('ttl_in', np.uint32),\n    ('ttl_out', np.uint32),\n    ('spi_perf_counter', np.uint32),\n    ('reserved', np.uint64)\n])\n\nrecord_dtype = np.dtype([\n    ('video_timestamp', np.uint64),\n    ('metadata', metadata_dtype)\n])\n\ndef read_XDAQFrameData_np(filename: str) -&gt; np.ndarray:\n    with open(filename, 'rb') as f:\n        data = f.read()\n    return np.frombuffer(data, dtype=record_dtype)\n\ndef map_rhd_to_video(neural_timestamps: np.ndarray, video_timestamps: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    For each neural timestamp, find the video frame index for which the video timestamp\n    is the largest value less than or equal to the neural timestamp.\n    \"\"\"\n    indices = np.searchsorted(video_timestamps, neural_timestamps, side='right') - 1\n    indices[indices &lt; 0] = 0\n    return indices\n\nif __name__ == \"__main__\":\n    if len(sys.argv) &lt; 3:\n        print(f\"Usage: python {sys.argv[0]} &lt;rhd_file_name&gt; &lt;xdaq_file_name&gt;\")\n        sys.exit(1)\n\n    rhd_data = read_data(sys.argv[1])\n    xdaq_data = read_XDAQFrameData_np(sys.argv[2])\n\n    rhd_timestamps = rhd_data[\"t_amplifier\"]\n    video_timestamps = xdaq_data[\"video_timestamp\"]\n\n    mapped_indices = map_rhd_to_video(rhd_timestamps, video_timestamps)\n    target_index_rhd = 0\n    target_index_video = mapped_indices[target_index_rhd]\n    print(f\"index_rhd: {target_index_rhd}, index_video: {target_index_video}\")\n    print(f\"video_timestamp: {video_timestamps[target_index_video]}, rhd_timestamp: {rhd_timestamps[target_index_rhd]}\")\n    print(f\"video_metadata: {xdaq_data['metadata'][target_index_video]}\")\n</code></pre> <p>Usage:</p> <pre><code>python XDAQFrameData.py &lt;intan_data_file_name&gt; &lt;xdaq_data_file_name&gt;\n</code></pre> <p>Expected output:</p> <pre><code>Reading Intan Technologies RHD Data File, Version 3.3\n\nFound 128 amplifier channels.\nFound 6 auxiliary input channels.\nFound 0 supply voltage channels.\nFound 0 board ADC channels.\nFound 8 board digital input channels.\nFound 0 board digital output channels.\nFound 0 temperature sensors channels.\n\nFile contains 28.915 seconds of data.  Amplifiers were sampled at 30.00 kS/s.\n\nAllocating memory for data...\nReading data from file...\n10% done...\n20% done...\n30% done...\n40% done...\n50% done...\n60% done...\n70% done...\n80% done...\n90% done...\nParsing data...\nNo missing timestamps in data.\nDone!  Elapsed time: 1.1 seconds\nindex_rhd: 0, index_video: 0\nvideo_timestamp: 26213000000, rhd_timestamp: 0.0\nvideo_metadata: (78118894449, 0, 0, 0, 809483121, 0)\n</code></pre>"},{"location":"usb-cameras/","title":"USB Cameras","text":""},{"location":"usb-cameras/#uvc-camera","title":"UVC Camera","text":"<p>The Universal Video Class (UVC) camera is a standard USB camera that adheres to the UVC protocol, offering plug-and-play support with modern operating systems. However, while UVC cameras are widely supported, their performance can vary substantially based on factors such as sensor design, cable quality, and especially the available USB bandwidth.</p> <p>We have successfully tested the following camera configuration on our system:</p> Camera Resolution FPS Max. Cameras USB UVC Camera 1280x720 30 4 2.0 <p>Note</p> <p>Some camera models may not achieve these performance metrics due to limitations in USB bandwidth acquisition. In multi-camera setups or when a single camera requires higher data throughput, the available USB bandwidth can become a bottleneck, potentially resulting in lower resolution or frame rates than expected. It is recommended to verify camera and system compatibility\u2014especially regarding USB bandwidth\u2014when planning your deployment.</p>"},{"location":"user-manual/","title":"User manual","text":""},{"location":"user-manual/#overview","title":"Overview","text":"<p>ThorVision is a GUI app designed for seamless control and video capture from USB cameras on the XDAQ AIO. This user manual provides instructions on how to use the features of the application effectively.</p> <pre><code>graph LR;\n    subgraph PC[\"PC\"]\n        subgraph CC[Camera Control Software]\n            TV(ThorVision)\n        end\n        subgraph DA[Data Acquisition Software]\n            RHX(XDAQ RHX)\n            OE(Open Ephys GUI)\n        end\n    end\n\n    XDAQ(XDAQ AIO)\n\n    subgraph CAMS[Cameras]\n        CAM1(Camera 1)\n        CAM2(Camera 2)\n        CAM3(Camera 3)\n        CAM4(Camera 4)\n    end\n\n    subgraph XH[X-Headstage]\n        x6R1(x6R)\n        x6R2(x6R)\n        x6R3(x6R)\n        x6R4(x6R)\n    end\n\n    XDAQ --&gt;|Thunderbolt| PC;\n    CAM1 --&gt;|USB| XDAQ;\n    CAM2 --&gt;|USB| XDAQ;\n    CAM3 --&gt;|USB| XDAQ;\n    CAM4 --&gt;|USB| XDAQ;\n\n    x6R1 --&gt;|HDMI| XDAQ;\n    x6R2 --&gt;|HDMI| XDAQ;\n    x6R3 --&gt;|HDMI| XDAQ;\n    x6R4 --&gt;|HDMI| XDAQ;\n\n    click XDAQ \"https://www.kontex.io/xdaq\" \"Go to XDAQ page\" _blank\n    click RHX \"https://github.com/kontex-neuro/Intan-RHX\" \"Go to XDAQ RHX page\" _blank\n    click OE \"https://open-ephys.org/gui\" \"Go to Open Ephys GUI page\" _blank\n    click TV \"https://github.com/kontex-neuro/ThorVision\" \"Go to ThorVision page\" _blank</code></pre>"},{"location":"user-manual/#hardware-requirements","title":"Hardware Requirements","text":"<ul> <li>PC: Mac (Apple silicon only) and Windows with a Thunderbolt 3.0 port (or higher).</li> <li>XDAQ AIO.</li> <li>Thunderbolt 3.0 Cable (or higher).</li> <li>UVC (USB Video Class) Cameras.</li> </ul>"},{"location":"user-manual/#installation","title":"Installation","text":""},{"location":"user-manual/#panels","title":"Panels","text":""},{"location":"user-manual/#1-camera-status","title":"1. Camera Status","text":"<p>Display the list and number of currently connected cameras. Select a camera from the list to access its settings in the Camera Specification Panel. </p>"},{"location":"user-manual/#2-overall-recording-settings-control","title":"2. Overall Recording Settings &amp; Control","text":"<p>Saving Options: Choose between:</p> <ul> <li>Continuous: Record a single, uninterrupted video file for the entire recording session.</li> <li>Split Record: Record multiple video files, each divided into predefined segments (e.g., 5 seconds, 10 seconds).</li> </ul> <p>Record Path: Click <code>...</code> button to select the folder for saving recordings.</p> <p>Folder Name: Choose between:</p> <ul> <li>Automatically generated: folder name in <code>YYYY-MM-DD_HH-MM-SS</code> format.</li> <li>Custom: Specify a custom folder name.</li> </ul> <p>Note</p> <p>The default record path:</p> <p>Windows: <code>C:/Users/&lt;user_name&gt;/Documents/ThorVision/</code></p> <p>macOS: <code>/Users/&lt;user_name&gt;/Documents/ThorVision/</code></p>"},{"location":"user-manual/#3-xdaq-status","title":"3. XDAQ Status","text":"<ul> <li>Connecting...: is displayed when XDAQ AIO is not yet connected or currently connecting.</li> <li>Connected: is displayed when XDAQ AIO is connected.</li> </ul> <p>The status transition may take some time, please be patient.</p>"},{"location":"user-manual/#4-camera-specification-panel","title":"4. Camera Specification Panel","text":"<p>Edit camera names, configure the <code>Quality</code>, and <code>Codec</code> in this area.</p>"},{"location":"user-manual/#camera-feed","title":"Camera Feed","text":""},{"location":"user-manual/#1-camera-views","title":"1. Camera Views","text":"<p>View stream windows under different scales.</p>"},{"location":"user-manual/#2-live-preview-window","title":"2. Live Preview Window","text":"<p>View live streams from cameras on the XDAQ AIO.</p>"},{"location":"user-manual/#3-information-icon","title":"3. Information Icon","text":"<p>Click to display live metadata and configured recording settings from cameras on the XDAQ AIO.</p>"},{"location":"user-manual/#setup-guide","title":"Setup Guide","text":""},{"location":"user-manual/#pre-launch-checklist","title":"Pre-Launch Checklist","text":"<ol> <li>Ensure a Thunderbolt 3.0 (or higher) cable connects the XDAQ AIO and the computer. </li> <li>Verify that the connectors are firmly seated.</li> <li>Confirm all cameras are firmly connected to the XDAQ AIO.</li> <li>Connect a Brainwave simulator to the XDAQ AIO using a 3.5mm jack to BNC wire.</li> <li>Connect the 3.5mm Jack to the \"Pulse\" port on the Brainwave simulator.</li> <li>Connect the BNC to the Digital In port on the front panel of the XDAQ AIO.</li> </ol>"},{"location":"user-manual/#launch-sequence","title":"Launch Sequence","text":"<p>Follow this exact order:</p> <ol> <li>Power on XDAQ AIO.</li> <li>Launch Open Ephys GUI or XDAQ-RHX first.</li> <li>Wait until the chosen application finishes its initialization.</li> <li>Launch ThorVision.</li> <li>Allow 1\u20132 minutes for ThorVision to connect.</li> <li>If the connection fails, retry the entire launch sequence from the start.</li> </ol>"},{"location":"user-manual/#camera-setup","title":"Camera Setup","text":"<ol> <li> <p>Once ThorVision connects to the XDAQ AIO, check the camera status panel to confirm all connected cameras are listed. If not, check the cable connections.</p> <ul> <li>INFO: Before assigning <code>Quality</code> and <code>Codec</code>, you can still hot-plug cameras to the XDAQ AIO. It may take a few seconds for the XDAQ AIO to recognize a newly connected camera.</li> </ul> <p></p> </li> <li> <p>On the right panel in ThorVision, assign a unique name, <code>Quality</code> and <code>Codec</code> to the selected camera. Before recording, make sure every camera on the list has both a <code>Quality</code> and a <code>Codec</code> assigned.</p> </li> </ol> <p>Tip</p> <ul> <li> <p>If the preview stream doesn't appear within 10 seconds, re-select the same <code>Quality</code> / <code>Codec</code> settings to refresh the view.</p> </li> <li> <p>If the camera-naming function behaves abnormally, restart the ThorVision interface and try again.</p> </li> </ul> <p>IMPORTANT</p> <ul> <li> <p>Do NOT assign the same name to different cameras. This can cause file overwrites during recording sessions.</p> </li> <li> <p>Do NOT change <code>Quality</code> / <code>Codec</code> once the preview has started. This can cause the camera to freeze.</p> </li> </ul> <ol> <li>Select a camera you want to edit.</li> <li>Assign a unique name.</li> <li>Configure <code>Quality</code> &amp; <code>Codec</code>.</li> </ol> <ol> <li>     To view camera activities (e.g., DI triggers), press the Information Icon in each preview window.      The <code>DI word</code> will show the channel number when the voltage in a certain Digital In BNC port is pulled to high.     <ul> <li>INFO: If the timestamp stops renewing or stays at zero during preview or recording, the camera is offline. Repeat the Launch Sequence.</li> </ul> </li> <li>     Check the recording settings (e.g., file interval, saving location, file name), and then press <code>REC</code>.   </li> </ol> <p>IMPORTANT</p> <p>When restarting a recording session, WAIT 5 SECONDS after stopping before pressing the record button again. Do not consecutively press the button more than one time!</p>"},{"location":"user-manual/#recording-tips","title":"Recording Tips","text":"<p>Configure the camera\u2019s recording settings to view the real time camera feed. The same settings will also be applied to video recording.</p> <p></p> <p>Press the <code>REC</code> button to start recording on all connected cameras simultaneously. The Stop Recording button works the same way. In the pop-up window, you can review the recording specifications. Use unique camera names only.</p> <p></p> <p>If XDAQ is disconnected, ThorVision will automatically stop recording.</p> <p></p> <p>You must stop recording before closing the ThorVision app.</p> <p></p>"},{"location":"user-manual/#golden-rules-tl-dr","title":"Golden Rules (TL; DR)","text":"<ul> <li>Launch Order is Critical: XDAQ AIO &gt;&gt;&gt; OE GUI / RHX &gt;&gt;&gt; ThorVision.</li> <li>Set the <code>Quality</code> / <code>Codec</code> once and never change it during the session.</li> <li>Use unique camera names only.</li> <li>Do not hot-plug cameras while recording.</li> <li>Wait at least 5 seconds after stopping a recording before starting a new one.</li> </ul>"},{"location":"xdaq-metadata/","title":"XDAQ Metadata","text":""},{"location":"xdaq-metadata/#data-structure","title":"Data Structure","text":"<pre><code>graph LR;\n    A(XDAQFrameData);\n    A --&gt;|8 bytes| B(FPGA Timestamp);\n    A --&gt;|4 bytes| C(Rhythm Timestamp);\n    A --&gt;|4 bytes| D(TTL In);\n    A --&gt;|4 bytes| E(TTL Out);\n    A --&gt;|4 bytes| F(SPI Performance Counter);\n    A --&gt;|8 bytes| G(Reserved);</code></pre> <p><code>XDAQFrameData</code> is embedded into camera frames captured by XDAQ AIO and streamed live to a PC via Thunderbolt. Each recorded frame contains both the JPEG encoded image data and its associated XDAQ metadata.</p> <p>Note</p> <p>Record H.265 encoded videos (coming soon)</p> <pre><code>graph LR;\n    A(PtsMetadata);\n    A --&gt;|8 bytes| B(PTS);\n    A --&gt;|32 bytes| C(XDAQFrameData);</code></pre>"},{"location":"xdaq-metadata/#file-extension","title":"File Extension","text":"<p><code>PtsMetadata</code> is saved as a flat binary file, containing continuous metadata associated with video frames for further metadata processing.</p>"}]}